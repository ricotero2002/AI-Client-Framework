# AI Client Framework

Un framework agn√≥stico y extensible para orquestar m√∫ltiples LLMs (OpenAI, Gemini, etc.) con soporte nativo para **Prompt Engineering Estructurado**, **Caching Optimization** y **Workflows Agenciales**.

## üéØ Core Features

- **Multi-Provider Unified API**: Interfaz polim√≥rfica para OpenAI y Gemini.
- **Structured Prompt Engine**: Clase `Prompt` robusta con separaci√≥n l√≥gica de contexto (System, Few-Shot, User).
- **Advanced Caching Strategy**: An√°lisis de tokens est√°ticos/din√°micos para maximizar el Cache Hit Ratio (Context Caching).
- **Structured Outputs (JSON/Pydantic)**: Validaci√≥n de esquemas de salida y parsing autom√°tico integrado.
- **Template System**: Interpolaci√≥n de variables `[[variable]]` y validaci√≥n de integridad.
- **LangGraph Ready**: Integraci√≥n directa para construir grafos de estado y agentes complejos.

## üìÅ Tech Stack & Structure

```
IA/
‚îú‚îÄ‚îÄ client_factory.py       # Factory Pattern para instanciaci√≥n din√°mica de proveedores
‚îú‚îÄ‚îÄ prompt.py               # Motor de prompts estructurados, validaci√≥n y templates
‚îú‚îÄ‚îÄ base_client.py          # Abstract Base Class (ABC) para estandarizaci√≥n de contratos
‚îú‚îÄ‚îÄ prompt_optimizer.py     # An√°lisis de tokens y heur√≠sticas de caching
‚îú‚îÄ‚îÄ langgraph_prueba.py     # Implementaci√≥n de referencia para flujos agenciales
‚îî‚îÄ‚îÄ config.py               # Gesti√≥n centralizada de modelos y pricing
```

## üöÄ Quick Start

### 1. Instalaci√≥n
```bash
pip install -r requirements.txt
```

### 2. Configuraci√≥n (.env)
```env
OPENAI_API_KEY=-...
GEMINI_API_KEY=...
```

### 3. Usage: Structured Prompting & Pydantic
Generaci√≥n de contenido con validaci√≥n de esquema estricta.

```python
from client_factory import create_client
from prompt import Prompt
from pydantic import BaseModel

# Definir esquema de salida esperado
class AnalysisResult(BaseModel):
    sentiment: str
    key_points: list[str]
    confidence_score: float

client = create_client('gemini') # o 'openai'
client.select_model('gemini-1.5-pro')

# Construcci√≥n del Prompt Estructurado
prompt = (
    Prompt()
    .set_system("Eres un analista de datos senior.")
    .add_few_shot_example(
        user="Analiza: 'El producto es lento pero funcional'", 
        assistant='{"sentiment": "neutral", "confidence_score": 0.8}'
    )
    .set_user_input("Analiza este feedback: [[feedback]]")
    .set_variable("feedback", "La nueva UI es incre√≠ble y muy r√°pida.")
    .set_output_schema(AnalysisResult) # Pydantic binding
)

# Ejecuci√≥n
response, metadata = client.get_response(
    prompt, 
    response_schema=prompt.get_output_schema()
)

print(response) # Instancia validada de AnalysisResult o dict
```

### 4. Usage: Agentic Workflow (LangGraph)
Ejemplo de integraci√≥n en grafos de estado (`langgraph_prueba.py`).

```python
def ideation_node(state: AgentState):
    client = ClientFactory.create_client('openai')
    prompt = Prompt().set_system("Generate innovative ideas...").set_user_input(state['topic'])
    response, _ = client.get_response(prompt)
    return {"idea": response}

workflow = StateGraph(AgentState)
workflow.add_node("ideation", ideation_node)
# ... compilar y ejecutar
```

## ÔøΩ Performance & Optimization

- **Token Counting**: Integraci√≥n con `tiktoken` (OpenAI) y APIs nativas.
- **Cost Estimation**: Estimaci√≥n en tiempo real basada en pricing configurable (`config.py`).
- **Cache Analytics**: `client.optimize_prompt_for_caching(messages)` analiza el payload para recomendar estrategias de `TTL` y orden de mensajes.

## ü§ù Extensibility

Para agregar un nuevo proveedor (ej. Claude), implementar `BaseAIClient` y registrar en `ClientFactory`. El `Prompt` class es agn√≥stico al modelo.

---
*License: MIT | Contribuciones bienvenidas mediante PRs.*
