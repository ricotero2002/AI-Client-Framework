# Gu√≠a de Uso - Proyecto RAG

## üöÄ Inicio R√°pido

### 1. Instalaci√≥n de Dependencias

```bash
# Instalar todas las dependencias necesarias
pip install -r requirements.txt

Desde rag_practice_proyect
```

### 2. Configuraci√≥n

Crea un archivo `.env` en la ra√≠z del proyecto:

```bash
# Copiar el template
cp .env.example .env
```

Edita `.env` y agrega tus API keys:

```env
OPENAI_API_KEY=tu_api_key_aqui
GEMINI_API_KEY=tu_api_key_aqui
DEFAULT_LLM_PROVIDER=openai
DEFAULT_MODEL=gpt-3.5-turbo
```

### 3. Setup Inicial

```bash
# Cargar datos y crear vector database
python setup.py
```

Este script:
- Descarga el dataset de Kaggle
- Procesa las recetas
- Genera embeddings
- Crea la base de datos vectorial con ChromaDB

### 4. Ejecutar Experimentos

```bash
# Ejecutar todos los experimentos
python experiments/run_all_experiments.py
```

Esto evaluar√° las 6 estrategias RAG con 10 consultas de prueba.

## üìä Estrategias RAG Implementadas

### 1. **No RAG** (Baseline)
- Sin recuperaci√≥n de contexto
- Solo LLM puro
- √ötil como baseline de comparaci√≥n

### 2. **Naive RAG**
- Recuperaci√≥n ‚Üí Lectura ‚Üí Generaci√≥n
- Enfoque m√°s b√°sico de RAG
- Recupera top-k documentos por similitud

### 3. **Advanced RAG**
- Pre-recuperaci√≥n: Optimizaci√≥n de consultas
- Post-recuperaci√≥n: Re-ranking y filtrado
- Mejora significativa sobre Naive RAG

### 4. **Modular RAG**
- Arquitectura modular con componentes intercambiables
- Retriever, QueryProcessor, ContextBuilder
- F√°cil de personalizar y extender

### 5. **Agentic RAG**
- Agentes aut√≥nomos que toman decisiones
- Decide si necesita recuperar informaci√≥n
- Refina b√∫squedas autom√°ticamente

### 6. **Graph RAG**
- Basado en grafos de conocimiento
- Navegaci√≥n contextual entre recetas
- Encuentra relaciones entre ingredientes

## üìà M√©tricas Evaluadas

### Rendimiento
- **Latencia**: Tiempo de respuesta en ms
- **Costo**: Tokens y costo en USD

### Calidad
- **Relevancia**: Qu√© tan relevante es la respuesta
- **Claridad**: Qu√© tan clara es la respuesta
- **Concisi√≥n**: Qu√© tan concisa es la respuesta
- **Cumplimiento**: Si cumple con lo solicitado
- **Precisi√≥n Factual**: Si es correcta seg√∫n el contexto

## üîß Personalizaci√≥n

### Cambiar el Modelo LLM

Edita `.env`:
```env
DEFAULT_LLM_PROVIDER=gemini
DEFAULT_MODEL=gemini-pro
```

### Agregar Nuevas Consultas de Prueba

Edita `experiments/run_all_experiments.py`:
```python
TEST_QUERIES = [
    "Tu consulta personalizada aqu√≠",
    # ... m√°s consultas
]
```

### Crear una Nueva Estrategia RAG

1. Crea un archivo en `src/rag_strategies/`
2. Hereda de `BaseRAGStrategy`
3. Implementa `generate_response()`

Ejemplo:
```python
from src.rag_strategies.base_strategy import BaseRAGStrategy

class MiNuevaEstrategia(BaseRAGStrategy):
    def __init__(self):
        super().__init__("Mi Nueva Estrategia")
    
    def generate_response(self, query: str, **kwargs):
        # Tu implementaci√≥n aqu√≠
        pass
```

## üìÅ Estructura de Resultados

Despu√©s de ejecutar experimentos, encontrar√°s en `results/`:

- `experiment_results_YYYYMMDD_HHMMSS.json`: Resultados detallados
- `latency_comparison.png`: Comparaci√≥n de latencias
- `quality_comparison.png`: Comparaci√≥n de calidad
- `cost_vs_quality.png`: An√°lisis costo vs calidad
- `latency_vs_quality.png`: An√°lisis latencia vs calidad
- `quality_heatmap.png`: Heatmap de m√©tricas

## üéØ Ejemplos de Uso

### Usar una Estrategia Espec√≠fica

```python
from src.rag_strategies.advanced_rag import AdvancedRAGStrategy

# Crear estrategia
strategy = AdvancedRAGStrategy(top_k=10, final_k=5)

# Generar respuesta
result = strategy.generate_response("¬øRecetas veganas con quinoa?")

print(result["response"])
print(f"Latencia: {result['latency_ms']:.1f} ms")
print(f"Costo: ${result['cost_usd']:.4f}")
```

### Evaluar una Respuesta

```python
from src.evaluation.evaluator import RAGEvaluator

evaluator = RAGEvaluator()

metrics = evaluator.evaluate_response(
    query="¬øRecetas veganas con quinoa?",
    response="Aqu√≠ hay algunas recetas...",
    context=["Receta 1...", "Receta 2..."]
)

print(f"Score general: {metrics['overall_score']:.2f}")
print(f"Relevancia: {metrics['relevance']:.2f}")
```

### Analizar Resultados

```python
from src.evaluation.analyzer import ResultsAnalyzer
import json

# Cargar resultados
with open("results/experiment_results.json") as f:
    results = json.load(f)

# Analizar
analyzer = ResultsAnalyzer(results)
analyzer.print_summary()
analyzer.generate_visualizations(Path("results"))
```

## üêõ Troubleshooting

### Error: "No module named 'config'"
```bash
# Aseg√∫rate de ejecutar desde la ra√≠z del proyecto
cd rag_practice_project
python setup.py
```

### Error: "API key not found"
```bash
# Verifica que .env existe y tiene las keys correctas
cat .env
```

### Error al cargar dataset de Kaggle
```bash
# Configura Kaggle API
# Descarga kaggle.json desde https://www.kaggle.com/settings
# Col√≥calo en ~/.kaggle/kaggle.json (Linux/Mac) o %USERPROFILE%\.kaggle\kaggle.json (Windows)
```

## üìö Recursos Adicionales

- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)
- [OpenAI API](https://platform.openai.com/docs)
- [Google Gemini API](https://ai.google.dev/)

## üìÑ Licencia

Este proyecto es para fines educativos y de pr√°ctica.
