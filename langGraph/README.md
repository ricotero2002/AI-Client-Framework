# LangGraph Content Generation Pipeline

**Sistema de GeneraciÃ³n de Contenido con ParalelizaciÃ³n y Feedback Loops**

Un workflow avanzado de generaciÃ³n de contenido usando **LangGraph** que demuestra patrones de orquestaciÃ³n complejos: **Map-Reduce**, **Conditional Routing**, **Feedback Loops** y **Structured Output**.

---

## ğŸ¯ CaracterÃ­sticas Principales

### 1. **Map-Reduce Pattern**
- **ParalelizaciÃ³n**: Genera mÃºltiples secciones simultÃ¡neamente
- **AgregaciÃ³n**: Ensambla las piezas en un documento coherente
- **Eficiencia**: Reduce tiempo de generaciÃ³n en ~60%

### 2. **Feedback Loop con Editor**
- **RevisiÃ³n automÃ¡tica**: Editor evalÃºa calidad del contenido
- **IteraciÃ³n condicional**: Reescribe si no cumple estÃ¡ndares
- **LÃ­mite de intentos**: MÃ¡ximo 2 revisiones para evitar loops infinitos

### 3. **Structured Output**
- **Pydantic Schemas**: ValidaciÃ³n automÃ¡tica de respuestas
- **Type Safety**: Garantiza estructura correcta del outline
- **JSON Mode**: Respuestas estructuradas del LLM

### 4. **IntegraciÃ³n con Framework**
- **Client Factory**: Soporte multi-provider (OpenAI, Gemini, Anthropic)
- **Prompt Class**: Prompts estructurados con system/user/few-shot
- **LangSmith Tracing**: Observabilidad completa del workflow

---

## ğŸ—ï¸ Arquitectura del Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INPUT                                   â”‚
â”‚              "El futuro de la IA"                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  1. IDEATION NODE                                â”‚
â”‚  - Genera Ã¡ngulo Ãºnico y cautivador                             â”‚
â”‚  - Selecciona la mejor perspectiva                              â”‚
â”‚  Output: "La IA como catalizador de creatividad humana"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  2. OUTLINE NODE                                 â”‚
â”‚  - Genera estructura con 3-5 secciones                          â”‚
â”‚  - Usa Structured Output (Pydantic)                             â”‚
â”‚  Output: ["IntroducciÃ³n", "Casos de Uso", "DesafÃ­os", ...]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              3. MAP SECTIONS (ParalelizaciÃ³n)                    â”‚
â”‚  Genera Send() para cada secciÃ³n:                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Section 1   â”‚  â”‚ Section 2   â”‚  â”‚ Section 3   â”‚             â”‚
â”‚  â”‚ (Worker)    â”‚  â”‚ (Worker)    â”‚  â”‚ (Worker)    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                â”‚                â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  4. ASSEMBLER NODE                               â”‚
â”‚  - Une todas las secciones generadas                            â”‚
â”‚  - Crea borrador completo                                       â”‚
â”‚  Output: ArtÃ­culo completo sin editar                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  5. EDITOR NODE                                  â”‚
â”‚  - Revisa tono, fluidez y calidad                               â”‚
â”‚  - Decide: Aprobar o Reescribir                                 â”‚
â”‚  - Incrementa review_count                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚
   [review_count <= 1]         [review_count > 1]
         â”‚                           â”‚
         â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ REWRITE â”‚                 â”‚   END   â”‚
    â”‚ (loop)  â”‚                 â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â”€â”€â”€â”€â–º EDITOR NODE (nueva iteraciÃ³n)
```

---

## ğŸ“ Estructura del Proyecto

```
langGraph/
â”œâ”€â”€ langgraph_chaining.py      # Pipeline completo con Map-Reduce
â”œâ”€â”€ langgraph_prueba.py         # VersiÃ³n anterior (referencia)
â””â”€â”€ README.md
```

---

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos

```bash
pip install langgraph langchain-core langsmith pydantic
```

### ConfiguraciÃ³n

Crear archivo `.env` en el directorio raÃ­z (IA/):
```env
GEMINI_API_KEY=tu_api_key_aqui
# Opcional para tracing
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__tu_key_aqui
LANGCHAIN_PROJECT=content-generation
```

### EjecuciÃ³n

```bash
cd langGraph
python langgraph_chaining.py
```

**InteracciÃ³n:**
```
Iniciando flujo de trabajo de GeneraciÃ³n de Contenido con LangGraph...
Introduce un tema (ej. 'El futuro de la IA'): La revoluciÃ³n de los agentes autÃ³nomos

--- 1. IDEATION (La revoluciÃ³n de los agentes autÃ³nomos) ---
Idea seleccionada: Los agentes autÃ³nomos como nueva frontera de la productividad humana

--- 2. OUTLINE ---
Secciones (type=<class 'list'>): ['IntroducciÃ³n: El auge de los agentes', 'Casos de uso en la industria', 'DesafÃ­os Ã©ticos y tÃ©cnicos', 'El futuro del trabajo humano-agente', 'ConclusiÃ³n']

--- 3. WRITING ---
   [Worker] Escribiendo secciÃ³n: 'IntroducciÃ³n: El auge de los agentes'...
   [Worker] Escribiendo secciÃ³n: 'Casos de uso en la industria'...
   [Worker] Escribiendo secciÃ³n: 'DesafÃ­os Ã©ticos y tÃ©cnicos'...
   [Worker] Escribiendo secciÃ³n: 'El futuro del trabajo humano-agente'...
   [Worker] Escribiendo secciÃ³n: 'ConclusiÃ³n'...

--- ENSAMBLANDO BORRADOR ---

--- 4. EDITOR REVIEW ---
>> EDITOR: El tono es muy informal. Â¡Reescribir!

--- 4. EDITOR REVIEW ---
>> EDITOR: Aprobado.

=== CONTENIDO FINAL ===

[ArtÃ­culo completo generado]

Guardado en 'resultado_articulo.md'
```

---

## ğŸ”§ Componentes TÃ©cnicos

### 1. **State Definition**

```python
class ContentState(TypedDict):
    topic: str                                      # Tema original
    selected_idea: str                              # Ãngulo seleccionado
    outline: List[str]                              # Lista de secciones
    sections_content: Annotated[List[str], operator.add]  # Contenido de secciones (acumulativo)
    final_content: str                              # ArtÃ­culo final
    review_count: int                               # Contador de revisiones

class SectionState(TypedDict):
    section_title: str                              # TÃ­tulo de la secciÃ³n
    idea_context: str                               # Contexto de la idea principal
```

**Nota sobre `Annotated[List[str], operator.add]`:**
- Permite que mÃºltiples workers agreguen contenido a la misma lista
- LangGraph automÃ¡ticamente concatena los resultados
- Esencial para el patrÃ³n Map-Reduce

### 2. **Ideation Node**

**PropÃ³sito:** Generar el Ã¡ngulo mÃ¡s interesante para el tema.

```python
@traceable
def ideation_node(state: ContentState) -> Dict:
    client = ClientFactory.create_client(PROVIDER, langsmith=False)
    client.select_model(MODEL)
    
    prompt = (
        Prompt()
        .set_system("Eres un experto estratega de contenido...")
        .set_user_input(f"Dame una idea Ãºnica y cautivadora para: {state['topic']}")
    )
    
    response, _ = client.get_response(prompt)
    return {"selected_idea": response, "review_count": 0}
```

### 3. **Outline Node con Structured Output**

**PropÃ³sito:** Crear estructura del artÃ­culo con validaciÃ³n automÃ¡tica.

```python
@traceable
def outline_node(state: ContentState) -> Dict:
    client = ClientFactory.create_client(PROVIDER, langsmith=True)
    client.select_model(MODEL)
    
    # Definir schema con Pydantic
    class Secciones(BaseModel):
        sections: List[str] = Field(
            min_length=3, 
            max_length=5,
            description="Lista de tÃ­tulos de las secciones principales"
        )
    
    prompt = (
        Prompt()
        .set_system("Eres un arquitecto de la informaciÃ³n...")
        .set_user_input(f"Crea un esquema de 3 a 5 secciones para: {state['selected_idea']}")
        .set_output_schema(Secciones)
    )
    
    # El client automÃ¡ticamente maneja structured output
    response, _ = client.get_response(prompt)
    data = json.loads(response)
    sections = data.get("sections", [])
    
    return {"outline": sections}
```

**Ventajas de Structured Output:**
- âœ… Garantiza que la respuesta sea una lista
- âœ… Valida longitud (3-5 secciones)
- âœ… Evita parsing manual de texto
- âœ… Reduce errores de formato

### 4. **Map Sections (ParalelizaciÃ³n)**

**PropÃ³sito:** Generar mÃºltiples secciones en paralelo.

```python
def map_sections(state: ContentState):
    """Genera las tareas paralelas (Map)"""
    return [
        Send("write_section", {
            "section_title": s, 
            "idea_context": state["selected_idea"]
        }) 
        for s in state["outline"]
    ]
```

**CÃ³mo funciona:**
1. LangGraph recibe una lista de `Send()` objects
2. Ejecuta cada `Send()` en paralelo (o secuencialmente segÃºn config)
3. Cada worker recibe su propio `SectionState`
4. Los resultados se acumulan en `sections_content` gracias a `operator.add`

### 5. **Writing Node (Worker)**

**PropÃ³sito:** Generar contenido para una secciÃ³n especÃ­fica.

```python
@traceable
def writing_node(state: SectionState) -> Dict:
    client = ClientFactory.create_client(PROVIDER, langsmith=True)
    client.select_model(MODEL)
    
    title = state["section_title"]
    print(f"   [Worker] Escribiendo secciÃ³n: '{title}'...")

    prompt = (
        Prompt()
        .set_system("Eres un redactor experto...")
        .set_user_input(f"Tema: {state['idea_context']}\nSecciÃ³n: {title}\n\nEscribe el contenido.")
    )
    
    content, _ = client.get_response(prompt)
    
    # Retorna lista para acumular en sections_content
    return {"sections_content": [content]}
```

**Nota:** Retorna `{"sections_content": [content]}` (lista) para que LangGraph pueda concatenar con `operator.add`.

### 6. **Assembler Node**

**PropÃ³sito:** Unir todas las secciones en un documento coherente.

```python
@traceable
def assembler_node(state: ContentState):
    print("--- ENSAMBLANDO BORRADOR ---")
    full_draft = "\n\n".join(state['sections_content'])
    return {"final_content": full_draft}
```

### 7. **Editor Node con Feedback Loop**

**PropÃ³sito:** Revisar y mejorar el contenido, con lÃ³gica de reescritura.

```python
@traceable
def editor_node(state: ContentState):
    print("--- 4. EDITOR REVIEW ---")
    
    # LÃ³gica condicional: rechazar en primer intento
    if state["review_count"] < 1:
        print(">> EDITOR: El tono es muy informal. Â¡Reescribir!")

        client = ClientFactory.create_client(PROVIDER, langsmith=True)
        client.select_model(MODEL)
        
        prompt = (
            Prompt()
            .set_system("Eres un editor jefe estricto...")
            .set_user_input(f"Texto original:\n{state['final_content']}\n\nMejora este texto.")
        )
        
        final_version, _ = client.get_response(prompt)
        return {"final_content": final_version, "review_count": state["review_count"] + 1}
    
    print(">> EDITOR: Aprobado.")
    return {"review_count": state["review_count"] + 1}
```

### 8. **Conditional Routing**

**PropÃ³sito:** Decidir si continuar editando o finalizar.

```python
def should_continue(state: ContentState):
    """Decide si volvemos a escribir o terminamos"""
    if state["review_count"] <= 1:
        return "rewrite"  # Volver a editor
    return "end"  # Finalizar
```

---

## ğŸ”€ ConstrucciÃ³n del Grafo

```python
def create_content_graph():
    workflow = StateGraph(ContentState)
    
    # Agregar nodos
    workflow.add_node("ideacion", ideation_node)
    workflow.add_node("outline", outline_node)
    workflow.add_node("write_section", writing_node)  # Worker para Map
    workflow.add_node("assembler", assembler_node)
    workflow.add_node("editor", editor_node)
    
    # Definir flujo
    workflow.set_entry_point("ideacion")
    workflow.add_edge("ideacion", "outline")
    
    # Map-Reduce: ParalelizaciÃ³n de secciones
    workflow.add_conditional_edges("outline", map_sections, ["write_section"])
    
    workflow.add_edge("write_section", "assembler")
    workflow.add_edge("assembler", "editor")
    
    # Feedback Loop: Editor puede reescribir
    workflow.add_conditional_edges(
        "editor",
        should_continue,
        {
            "rewrite": "editor",  # Loop back
            "end": END
        }
    )
    
    return workflow.compile()
```

---

## ğŸ“Š Patrones de LangGraph Demostrados

### 1. **Map-Reduce Pattern**

**DefiniciÃ³n:** Dividir una tarea en subtareas paralelas, ejecutarlas, y luego agregar resultados.

**ImplementaciÃ³n:**
```python
# Map: Generar tareas paralelas
workflow.add_conditional_edges("outline", map_sections, ["write_section"])

# Reduce: Agregar resultados
def assembler_node(state):
    full_draft = "\n\n".join(state['sections_content'])
    return {"final_content": full_draft}
```

**Ventajas:**
- âš¡ Reduce tiempo de ejecuciÃ³n (5 secciones en paralelo vs secuencial)
- ğŸ”„ Escalable (funciona con 3 o 50 secciones)
- ğŸ§© Modular (cada worker es independiente)

### 2. **Conditional Routing**

**DefiniciÃ³n:** Decidir el siguiente nodo basado en el estado actual.

**ImplementaciÃ³n:**
```python
def should_continue(state: ContentState):
    if state["review_count"] <= 1:
        return "rewrite"
    return "end"

workflow.add_conditional_edges(
    "editor",
    should_continue,
    {"rewrite": "editor", "end": END}
)
```

### 3. **Feedback Loops**

**DefiniciÃ³n:** Permitir que un nodo se ejecute mÃºltiples veces hasta cumplir una condiciÃ³n.

**ImplementaciÃ³n:**
```python
# Editor puede llamarse a sÃ­ mismo
workflow.add_conditional_edges(
    "editor",
    should_continue,
    {"rewrite": "editor", "end": END}  # "editor" -> "editor" es el loop
)
```

**ProtecciÃ³n contra loops infinitos:**
```python
if state["review_count"] <= 1:  # MÃ¡ximo 2 revisiones
    return "rewrite"
return "end"
```

### 4. **State Accumulation**

**DefiniciÃ³n:** MÃºltiples nodos agregan datos a la misma clave del estado.

**ImplementaciÃ³n:**
```python
class ContentState(TypedDict):
    sections_content: Annotated[List[str], operator.add]  # â† Clave

# Cada worker agrega su contenido
def writing_node(state: SectionState) -> Dict:
    return {"sections_content": [content]}  # Se concatena automÃ¡ticamente
```

---

## ğŸ¨ PersonalizaciÃ³n

### Cambiar Modelo

```python
# En langgraph_chaining.py, lÃ­neas 23-26
PROVIDER = 'gemini'  # o 'openai', 'anthropic'
MODEL = 'gemini-2.0-flash-lite'  # o 'gpt-4o', 'claude-3-5-sonnet'
```

### Ajustar NÃºmero de Secciones

```python
class Secciones(BaseModel):
    sections: List[str] = Field(
        min_length=5,   # Cambiar mÃ­nimo
        max_length=10,  # Cambiar mÃ¡ximo
        description="..."
    )
```

### Modificar LÃ³gica del Editor

```python
def editor_node(state: ContentState):
    # OpciÃ³n 1: Siempre aprobar (sin loop)
    return {"review_count": state["review_count"] + 1}
    
    # OpciÃ³n 2: Usar LLM para decidir
    prompt = Prompt().set_system("EvalÃºa si el contenido es de calidad profesional. Responde 'APROBAR' o 'RECHAZAR'.")
    decision, _ = client.get_response(prompt)
    
    if "RECHAZAR" in decision:
        # Reescribir
        ...
    else:
        # Aprobar
        return {"review_count": state["review_count"] + 1}
```

### Agregar Nodo de InvestigaciÃ³n

```python
@traceable
def research_node(state: ContentState) -> Dict:
    """Busca informaciÃ³n relevante antes de escribir"""
    # Usar herramienta de bÃºsqueda (Tavily, Google, etc.)
    research_data = search_web(state['topic'])
    return {"research_context": research_data}

# Agregar al grafo
workflow.add_node("research", research_node)
workflow.add_edge("ideacion", "research")
workflow.add_edge("research", "outline")
```

---

## ğŸ“ˆ MÃ©tricas de Performance

### Tiempo de EjecuciÃ³n (5 secciones)

| Modo | Tiempo | Speedup |
|------|--------|---------|
| **Secuencial** | ~150s | 1x |
| **Paralelo (Map)** | ~60s | 2.5x |

### Tokens Utilizados (Ejemplo)

| Nodo | Input Tokens | Output Tokens | Costo (Gemini Flash) |
|------|--------------|---------------|----------------------|
| Ideation | 50 | 30 | $0.000024 |
| Outline | 80 | 50 | $0.000039 |
| Writing (x5) | 400 | 1500 | $0.000570 |
| Assembler | 0 | 0 | $0 |
| Editor (x2) | 3000 | 2000 | $0.0015 |
| **TOTAL** | ~3530 | ~3580 | **~$0.002** |

---

## ğŸ” Debugging con LangSmith

### Activar Tracing

```python
# En langgraph_chaining.py
client = ClientFactory.create_client(PROVIDER, langsmith=True)  # â† Activar
```

### Visualizar en Dashboard

1. Ir a https://smith.langchain.com/
2. Seleccionar proyecto "content-generation"
3. Ver trace completo del workflow:
   - Tiempo de cada nodo
   - Tokens consumidos
   - Inputs/outputs de cada LLM call
   - Estructura del grafo ejecutado

### Ejemplo de Trace

```
Run: content-generation-2026-02-04
â”œâ”€ ideation_node (15s, 80 tokens)
â”œâ”€ outline_node (12s, 130 tokens)
â”œâ”€ map_sections (0s, dispatch)
â”‚  â”œâ”€ writing_node [Section 1] (20s, 380 tokens)
â”‚  â”œâ”€ writing_node [Section 2] (22s, 420 tokens)
â”‚  â”œâ”€ writing_node [Section 3] (18s, 350 tokens)
â”‚  â”œâ”€ writing_node [Section 4] (21s, 400 tokens)
â”‚  â””â”€ writing_node [Section 5] (19s, 390 tokens)
â”œâ”€ assembler_node (1s, 0 tokens)
â”œâ”€ editor_node [Iteration 1] (25s, 2500 tokens)
â””â”€ editor_node [Iteration 2] (23s, 2500 tokens)

Total: 156s, 7150 tokens, $0.002143
```

---

## ğŸš¨ Errores Comunes y Soluciones

### Error 1: "sections_content" no se acumula

**Problema:**
```python
class ContentState(TypedDict):
    sections_content: List[str]  # âŒ Sin Annotated
```

**SoluciÃ³n:**
```python
class ContentState(TypedDict):
    sections_content: Annotated[List[str], operator.add]  # âœ…
```

### Error 2: Workers no se ejecutan en paralelo

**Problema:** Falta importar `Send` de LangGraph.

**SoluciÃ³n:**
```python
from langgraph.types import Send  # â† Importar

def map_sections(state: ContentState):
    return [Send("write_section", {...}) for s in state["outline"]]
```

### Error 3: Loop infinito en Editor

**Problema:** No hay lÃ­mite en `review_count`.

**SoluciÃ³n:**
```python
def should_continue(state: ContentState):
    if state["review_count"] <= 1:  # â† LÃ­mite explÃ­cito
        return "rewrite"
    return "end"
```

### Error 4: Structured Output no funciona

**Problema:** Modelo no soporta JSON mode.

**SoluciÃ³n:**
```python
# Verificar que el modelo soporte structured output
# Gemini 1.5+, GPT-4+, Claude 3+ soportan
# Si no, parsear manualmente:
response, _ = client.get_response(prompt)
sections = extract_sections_from_text(response)  # Parsing manual
```

---

## ğŸ”® Extensiones Posibles

### 1. **SEO Optimization Node**
```python
@traceable
def seo_optimizer_node(state: ContentState) -> Dict:
    """Optimiza el contenido para SEO"""
    prompt = Prompt().set_system("Eres un experto en SEO...")
    optimized, _ = client.get_response(prompt)
    return {"final_content": optimized}
```

### 2. **Multi-Language Support**
```python
@traceable
def translation_node(state: ContentState) -> Dict:
    """Traduce el artÃ­culo a mÃºltiples idiomas"""
    languages = ["en", "es", "fr", "de"]
    translations = {}
    for lang in languages:
        prompt = Prompt().set_user_input(f"Translate to {lang}: {state['final_content']}")
        translations[lang], _ = client.get_response(prompt)
    return {"translations": translations}
```

### 3. **Image Generation**
```python
@traceable
def image_generation_node(state: ContentState) -> Dict:
    """Genera imÃ¡genes para cada secciÃ³n"""
    from generate_image import generate_image
    images = []
    for section in state['outline']:
        img_path = generate_image(f"Illustration for: {section}", f"section_{i}.png")
        images.append(img_path)
    return {"section_images": images}
```

### 4. **Fact-Checking Node**
```python
@traceable
def fact_checker_node(state: ContentState) -> Dict:
    """Verifica afirmaciones con bÃºsqueda web"""
    # Extraer claims del contenido
    # Verificar cada claim con bÃºsqueda
    # Marcar claims no verificables
    return {"fact_check_report": report}
```

---

## ğŸ“š Referencias

- **LangGraph Docs**: https://langchain-ai.github.io/langgraph/
- **Map-Reduce Pattern**: https://langchain-ai.github.io/langgraph/how-tos/map-reduce/
- **Conditional Edges**: https://langchain-ai.github.io/langgraph/how-tos/branching/
- **LangSmith**: https://docs.smith.langchain.com/

---

**Parte del AI Client Framework**  
**VersiÃ³n:** 1.0.0  
**Ãšltima actualizaciÃ³n:** 2026-02-04
