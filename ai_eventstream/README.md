# AI-EventStream: Agente de Procesamiento Sem√°ntico Distribuido

Sistema de procesamiento de IA distribuido y as√≠ncrono que utiliza Apache Kafka para ingesta masiva de eventos, Celery para procesamiento pesado de modelos de IA, y Redis como capa de memoria ultrarr√°pida.

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Apache Kafka   ‚îÇ ‚Üê Ingesta de datos masiva
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI API   ‚îÇ ‚Üê Orquestador as√≠ncrono
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Redis       ‚îÇ ‚Üê Broker + Cach√© Sem√°ntica
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Celery Workers  ‚îÇ ‚Üê Procesamiento de IA
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Componentes Principales

### 1. **Ingesta de Datos (Apache Kafka)**
- Sistema nervioso central del flujo de datos
- Recibe eventos masivos (rese√±as, logs, mensajes)
- Garantiza durabilidad e inmutabilidad

### 2. **Orquestador API (FastAPI)**
- Endpoints as√≠ncronos para env√≠o de tareas
- Consulta de estados y m√©tricas
- Totalmente no-bloqueante

### 3. **Procesamiento de IA (Celery + Workers)**
- Ejecuci√≥n distribuida de LLMs
- Escalado independiente seg√∫n carga
- Optimizado para tareas pesadas

### 4. **Cerebro y Memoria (Redis)**
- **Broker**: Intermediario entre FastAPI y Celery
- **Cach√© Sem√°ntica**: B√∫squeda vectorial con RedisVL
- **Async Client**: Conexi√≥n de baja latencia

## üì¶ Stack Tecnol√≥gico

| Componente      | Tecnolog√≠a    | Rol                                          |
|-----------------|---------------|----------------------------------------------|
| Backend         | FastAPI       | Gateway as√≠ncrono y manejo de endpoints      |
| Worker          | Celery        | Ejecuci√≥n distribuida de modelos de IA       |
| Broker/Cache    | Redis Stack   | Memoria RAM, broker y b√∫squeda vectorial     |
| Streaming       | Apache Kafka  | Ingesta de eventos inmutable y duradera      |
| Monitorizaci√≥n  | Flower        | Dashboard en tiempo real para tareas Celery  |
| Infraestructura | Docker        | Contenedores y hosting escalable            |


### ‚úÖ1: El N√∫cleo As√≠ncrono (FastAPI + Redis)
- [x] Setup de FastAPI con uvicorn
- [x] Cliente Redis as√≠ncrono (redis.asyncio)
- [x] Estructura de Cach√© Sem√°ntica con RedisVL
- [x] Endpoints b√°sicos de API

### ‚úÖ2: El M√∫sculo del Agente (Celery + IA)
- [x] Configuraci√≥n de Celery con Redis
- [x] Integraci√≥n con LLM (OpenAI/HuggingFace)
- [x] Optimizaci√≥n de workers (prefetch, acks_late)
- [x] Reinicio autom√°tico para evitar fugas de memoria

### ‚úÖ3: El Bus de Eventos (Apache Kafka)
- [x] Kafka Consumer independiente
- [x] Patr√≥n de disparo: Kafka ‚Üí Celery
- [x] Desacoplamiento completo
- [x] Persistencia de resultados en Redis

### ‚úÖ4: Memoria de Agente y L√≥gica Avanzada
- [x] L√≥gica de cach√© sem√°ntica
- [x] B√∫squeda vectorial (umbral > 0.8)
- [x] Rate limiting para APIs externas
- [x] Optimizaci√≥n de costos

### ‚úÖ5: Dockerizaci√≥n y Despliegue Cloud
- [x] Dockerfile multietapa
- [x] docker-compose.yml completo
- [x] Configuraci√≥n de variables de entorno
- [x] Endpoint p√∫blico /process

## üõ†Ô∏è Instalaci√≥n

### Requisitos Previos
- Python 3.11+
- Docker y Docker Compose
- Redis Stack
- Apache Kafka

### Instalaci√≥n Local

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales
```

### Usando Docker

```bash
# Levantar todos los servicios
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down
```

## üéØ Uso

### 1. Enviar una tarea para procesamiento

```python
import requests

response = requests.post(
    "http://localhost:8000/process",
    json={
        "text": "Analiza el sentimiento de esta rese√±a: El producto es excelente!",
        "task_type": "sentiment_analysis"
    }
)

task_id = response.json()["task_id"]
print(f"Task ID: {task_id}")
```

### 2. Consultar el estado de una tarea

```python
status_response = requests.get(f"http://localhost:8000/task/{task_id}")
print(status_response.json())
```

### 3. Enviar eventos a Kafka

```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

producer.send('datos_crudos', {
    'text': 'Texto para analizar',
    'metadata': {'source': 'web'}
})
```

## üìä Monitorizaci√≥n

### Flower (Celery Dashboard)
Accede a `http://localhost:5555` para ver:
- Tareas activas y completadas
- Workers disponibles
- M√©tricas de rendimiento

### API Metrics
Accede a `http://localhost:8000/metrics` para ver:
- Tareas procesadas
- Cache hit rate
- Latencia promedio

## üîß Configuraci√≥n Avanzada

### Optimizaci√≥n de Workers

```python
# celery_config.py
worker_prefetch_multiplier = 1  # Una tarea a la vez
task_acks_late = True           # Confirmar despu√©s de completar
worker_max_tasks_per_child = 100  # Reiniciar despu√©s de 100 tareas
```

### Cach√© Sem√°ntica

```python
# Umbral de similitud para cache hit
SEMANTIC_SIMILARITY_THRESHOLD = 0.8

# TTL de cach√© (en segundos)
CACHE_TTL = 3600  # 1 hora
```

## üöÄ Despliegue en Producci√≥n

### Railway/Render

1. Conectar el repositorio
2. Configurar variables de entorno:
   - `REDIS_URL`
   - `KAFKA_BOOTSTRAP_SERVERS`
   - `OPENAI_API_KEY`
3. Desplegar API y Workers por separado

### Variables de Entorno Requeridas

```env
# Redis
REDIS_URL=redis://localhost:6379

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# OpenAI
OPENAI_API_KEY=sk-...

# Configuraci√≥n
ENVIRONMENT=production
LOG_LEVEL=INFO
```

## üìà Caracter√≠sticas Principales

- ‚úÖ **Procesamiento As√≠ncrono**: FastAPI + Redis async
- ‚úÖ **Escalabilidad Horizontal**: Workers Celery independientes
- ‚úÖ **Cach√© Inteligente**: B√∫squeda vectorial sem√°ntica
- ‚úÖ **Ingesta Masiva**: Apache Kafka para eventos
- ‚úÖ **Optimizaci√≥n de Costos**: Reutilizaci√≥n de respuestas LLM
- ‚úÖ **Monitorizaci√≥n**: Flower + m√©tricas personalizadas
- ‚úÖ **Dockerizado**: Despliegue simple con docker-compose

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## üìù Licencia

MIT License - ver el archivo LICENSE para m√°s detalles

## üôè Agradecimientos

- FastAPI por el framework as√≠ncrono
- Celery por el procesamiento distribuido
- Redis por la velocidad y versatilidad
- Apache Kafka por la ingesta confiable
