services:
  # Redis Stack (incluye RedisVL para búsqueda vectorial)
  redis:
    image: redis/redis-stack:latest
    container_name: ai_eventstream_redis
    ports:
      - "6379:6379"
      - "8001:8001"  # RedisInsight UI
    volumes:
      - redis_data:/data
    environment:
      - REDIS_ARGS=--requirepass ${REDIS_PASSWORD:-}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai_eventstream_network

  # Apache Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: ai_eventstream_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - ai_eventstream_network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: ai_eventstream_kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - ai_eventstream_network

  kafka_ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    networks:
      - ai_eventstream_network

  # FastAPI Application
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: api
    container_name: ai_eventstream_api
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/2
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    volumes:
      - ./logs:/app/logs
      - .:/app
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1
    networks:
      - ai_eventstream_network
    restart: unless-stopped

  # Celery Worker
  worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: worker
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/2
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    volumes:
      - ./logs:/app/logs
      - .:/app
    command: celery -A celery_app worker --loglevel=info --concurrency=4 --max-tasks-per-child=100
    networks:
      - ai_eventstream_network
    restart: unless-stopped
    deploy:
      replicas: 2  # Múltiples workers para escalabilidad

  # Kafka Consumer
  kafka_consumer:
    build:
      context: .
      dockerfile: Dockerfile
      target: consumer
    container_name: ai_eventstream_kafka_consumer
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      worker:
        condition: service_started
    environment:
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/2
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    volumes:
      - ./logs:/app/logs
      - .:/app
    command: python kafka_consumer.py
    networks:
      - ai_eventstream_network
    restart: unless-stopped

  # Flower (Celery Monitoring)
  flower:
    build:
      context: .
      dockerfile: Dockerfile
      target: flower
    container_name: ai_eventstream_flower
    depends_on:
      - redis
      - worker
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/2
      - FLOWER_BASIC_AUTH=${FLOWER_BASIC_AUTH:-admin:admin123}
      - FLOWER_PERSISTENT=True
      - FLOWER_DB=/data/flower.db
      - FLOWER_STATE_SAVE_INTERVAL=5000
    volumes:
      - flower_data:/data
    command: celery -A celery_app flower --port=5555 --persistent=True --db=/data/flower.db
    networks:
      - ai_eventstream_network
    restart: unless-stopped

volumes:
  redis_data:
    driver: local
  flower_data:
    driver: local

networks:
  ai_eventstream_network:
    driver: bridge
